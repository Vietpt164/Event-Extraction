{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1713918,"sourceType":"datasetVersion","datasetId":1015825},{"sourceId":10324487,"sourceType":"datasetVersion","datasetId":6392416},{"sourceId":10340932,"sourceType":"datasetVersion","datasetId":6403388}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:51:49.749575Z","iopub.execute_input":"2025-01-04T20:51:49.749894Z","iopub.status.idle":"2025-01-04T20:51:50.066057Z","shell.execute_reply.started":"2025-01-04T20:51:49.749855Z","shell.execute_reply":"2025-01-04T20:51:50.065395Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ee-pretrain-biobert/trigger-detection-biobert.pt\n/kaggle/input/ee-pretrain-biobert/event-cls-biobert.pt\n/kaggle/input/ee-pretrained/event-classififcation-pretrained.pt\n/kaggle/input/ee-pretrained/trigger-detection-pretrained.pt\n/kaggle/input/genia-biomedical-event-dataset/train_data.csv\n/kaggle/input/genia-biomedical-event-dataset/test_data.csv\n/kaggle/input/genia-biomedical-event-dataset/dev_data.csv\n/kaggle/input/genia-biomedical-event-dataset/GE11-LICENSE\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport pandas as pd\nfrom transformers import BertTokenizerFast, BertForTokenClassification, BertTokenizer, BertModel\nimport torch\nfrom torch import nn\nfrom collections import OrderedDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:51:50.067157Z","iopub.execute_input":"2025-01-04T20:51:50.067547Z","iopub.status.idle":"2025-01-04T20:51:59.554123Z","shell.execute_reply.started":"2025-01-04T20:51:50.067517Z","shell.execute_reply":"2025-01-04T20:51:59.553074Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Define the BERT-based classifier\nclass BertClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(BertClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        dropout_output = self.dropout(pooled_output)\n        return self.classifier(dropout_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:51:59.555744Z","iopub.execute_input":"2025-01-04T20:51:59.556268Z","iopub.status.idle":"2025-01-04T20:51:59.561708Z","shell.execute_reply.started":"2025-01-04T20:51:59.556241Z","shell.execute_reply":"2025-01-04T20:51:59.560868Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load trigger detection model\ndef load_trigger_model(model_path, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n    model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=2)\n    state_dict = torch.load(model_path, map_location=device)\n    model.load_state_dict(state_dict)\n    model.to(device)\n    model.eval()\n    return tokenizer, model, device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:51:59.563020Z","iopub.execute_input":"2025-01-04T20:51:59.563301Z","iopub.status.idle":"2025-01-04T20:51:59.661090Z","shell.execute_reply.started":"2025-01-04T20:51:59.563280Z","shell.execute_reply":"2025-01-04T20:51:59.660139Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load event classification model\ndef load_event_model(model_path, num_classes, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    model = BertClassifier(num_classes=num_classes)\n    state_dict = torch.load(model_path, map_location=device)\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        if k.startswith('module.'):\n            k = k[len('module.'):]\n        new_state_dict[k] = v\n    model.load_state_dict(new_state_dict)\n    model.to(device)\n    model.eval()\n    return tokenizer, model, device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:51:59.662007Z","iopub.execute_input":"2025-01-04T20:51:59.662379Z","iopub.status.idle":"2025-01-04T20:51:59.684012Z","shell.execute_reply.started":"2025-01-04T20:51:59.662352Z","shell.execute_reply":"2025-01-04T20:51:59.683335Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Trigger prediction function\ndef trigger_predict(sentence, tokenizer, model, device, max_len=512):\n    words = sentence.split()\n    encoding = tokenizer(\n        words,\n        is_split_into_words=True,\n        return_offsets_mapping=False,\n        padding='max_length',\n        truncation=True,\n        max_length=max_len,\n        return_tensors='pt'\n    )\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n    logits = outputs.logits\n    preds = torch.argmax(logits, dim=-1).squeeze().cpu().numpy()\n    word_ids = encoding.word_ids(batch_index=0)\n    labels = []\n    previous_word_idx = None\n    for idx, word_idx in enumerate(word_ids):\n        if word_idx is None:\n            continue\n        elif word_idx != previous_word_idx:\n            labels.append(preds[idx])\n            previous_word_idx = word_idx\n    return list(zip(words, labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:51:59.684965Z","iopub.execute_input":"2025-01-04T20:51:59.685278Z","iopub.status.idle":"2025-01-04T20:51:59.700437Z","shell.execute_reply.started":"2025-01-04T20:51:59.685250Z","shell.execute_reply":"2025-01-04T20:51:59.699702Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Event prediction function\ndef predict_event(word, tokenizer, model, device, max_len=32):\n    tokenizer_output = tokenizer(word, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_len)\n    input_ids = tokenizer_output[\"input_ids\"].to(device)\n    attention_mask = tokenizer_output[\"attention_mask\"].to(device)\n    with torch.no_grad():\n        logits = model(input_ids, attention_mask)\n        preds = torch.argmax(logits, dim=1).cpu().item()\n    return preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:51:59.701212Z","iopub.execute_input":"2025-01-04T20:51:59.701499Z","iopub.status.idle":"2025-01-04T20:51:59.720727Z","shell.execute_reply.started":"2025-01-04T20:51:59.701470Z","shell.execute_reply":"2025-01-04T20:51:59.720110Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Evaluate dataset and compute metrics\ndef evaluate_and_compute_metrics(csv_file, trigger_model_path, event_model_path, index_to_label, label_to_index, output_file):\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    num_classes = 9\n\n    trigger_tokenizer, trigger_model, _ = load_trigger_model(trigger_model_path, device)\n    event_tokenizer, event_model, _ = load_event_model(event_model_path, num_classes, device)\n\n    data = pd.read_csv(csv_file)\n    true_labels = []\n    pred_labels = []\n\n    for _, row in data.iterrows():\n        sentence = row[\"Sentence\"]\n        trigger_words = str(row[\"TriggerWord\"]).split(';')[:-1] if pd.notna(row[\"TriggerWord\"]) else []\n        trigger_locs = [(int(x)-1) for x in str(row[\"TriggerWordLoc\"]).split(';')[:-1]] if pd.notna(row[\"TriggerWordLoc\"]) else []\n        event_types = str(row[\"EventType\"]).split(';')[:-1] if pd.notna(row[\"EventType\"]) else []\n\n        # Predict triggers and filter out words predicted as trigger\n        trigger_predictions = trigger_predict(sentence, trigger_tokenizer, trigger_model, device)\n        predicted_trigger_words = [word for word, label in trigger_predictions if label == 1]\n\n        # True labels and predicted labels       \n        true_events = ['No Event'] * len(sentence.split())\n        for trigger_loc, event in zip(trigger_locs,event_types):\n            true_events[trigger_loc] = event\n        for item in true_events:\n            true_labels.append(item)\n\n        predict_events = ['No Event' if x[1] == 0 else index_to_label[predict_event(x[0], event_tokenizer, event_model, device)] for x in trigger_predictions]\n        for item in predict_events:\n            pred_labels.append(item)\n        \n\n    # Calculate metrics\n    accuracy = accuracy_score(true_labels, pred_labels)\n    conf_matrix = confusion_matrix(true_labels, pred_labels, labels=list(label_to_index.keys()))\n    report = classification_report(true_labels, pred_labels, labels=list(label_to_index.keys()), digits = 4)\n\n    print(\"Accuracy:\", accuracy)\n    print(\"Confusion Matrix:\")\n    print(conf_matrix)\n    print(\"Classification Report:\")\n    print(report)\n\n    # Save results to file\n    results = pd.DataFrame({\n        \"True_Labels\": true_labels,\n        \"Predicted_Labels\": pred_labels\n    })\n    results.to_csv(output_file, index=False)\n    print(f\"Results saved to {output_file}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:51:59.721572Z","iopub.execute_input":"2025-01-04T20:51:59.721816Z","iopub.status.idle":"2025-01-04T20:51:59.736767Z","shell.execute_reply.started":"2025-01-04T20:51:59.721798Z","shell.execute_reply":"2025-01-04T20:51:59.736191Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"# Paths and parameters\ncsv_file = '/kaggle/input/genia-biomedical-event-dataset/dev_data.csv'\ntrigger_model_path = '/kaggle/input/ee-pretrained/trigger-detection-pretrained.pt'\nevent_model_path = '/kaggle/input/ee-pretrained/event-classififcation-pretrained.pt'\nindex_to_label = {\n    0: 'Negative_regulation', \n     1: 'Gene_expression', \n     2: 'Regulation', \n     3: 'Transcription', \n     4: 'Positive_regulation', \n     5: 'Binding', \n     6: 'Localization', \n     7: 'Phosphorylation', \n     8: 'Protein_catabolism', \n}\n\nlabel_to_index = {\n    \"Negative_regulation\": 0,\n    \"Gene_expression\": 1,\n    \"Regulation\": 2,\n    \"Transcription\": 3,\n    \"Positive_regulation\": 4,\n    \"Binding\": 5,\n    \"Localization\": 6,\n    \"Phosphorylation\": 7,\n    \"Protein_catabolism\": 8,\n    \"No Event\": 9\n}\noutput_file = '/kaggle/working/evaluation_results.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:58:19.401442Z","iopub.execute_input":"2025-01-04T20:58:19.401960Z","iopub.status.idle":"2025-01-04T20:58:19.409362Z","shell.execute_reply.started":"2025-01-04T20:58:19.401920Z","shell.execute_reply":"2025-01-04T20:58:19.408079Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Run evaluation\nevaluate_and_compute_metrics(csv_file, trigger_model_path, event_model_path, index_to_label, label_to_index, output_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T20:58:21.626989Z","iopub.execute_input":"2025-01-04T20:58:21.627358Z","iopub.status.idle":"2025-01-04T21:00:16.144567Z","shell.execute_reply.started":"2025-01-04T20:58:21.627332Z","shell.execute_reply":"2025-01-04T21:00:16.143361Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n<ipython-input-4-3ec8a071fc2b>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(model_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.982575576611726\nConfusion Matrix:\n[[  190     0     4     0     9     0     0     0     0   122]\n [    1   416     0     2    35     0     5     0     0    96]\n [    0     0    90     0    10     1     0     0     0    93]\n [    0    20     0    42     6     0     0     0     0    47]\n [    1     3     3     1   409     0     0     2     0   263]\n [    1     0     0     0     4   142     0     0     0   108]\n [    0     1     0     0     1     0    30     0     0    11]\n [    0     0     0     0     0     0     0    48     0    25]\n [    0     0     0     0     0     0     0     0    14     4]\n [   65    90    46    26   143    47     5    10     2 72660]]\nClassification Report:\n                     precision    recall  f1-score   support\n\nNegative_regulation     0.7364    0.5846    0.6518       325\n    Gene_expression     0.7849    0.7495    0.7668       555\n         Regulation     0.6294    0.4639    0.5341       194\n      Transcription     0.5915    0.3652    0.4516       115\nPositive_regulation     0.6629    0.5997    0.6297       682\n            Binding     0.7474    0.5569    0.6382       255\n       Localization     0.7500    0.6977    0.7229        43\n    Phosphorylation     0.8000    0.6575    0.7218        73\n Protein_catabolism     0.8750    0.7778    0.8235        18\n           No Event     0.9895    0.9941    0.9918     73094\n\n           accuracy                         0.9826     75354\n          macro avg     0.7567    0.6447    0.6932     75354\n       weighted avg     0.9813    0.9826    0.9817     75354\n\nResults saved to /kaggle/working/evaluation_results.csv.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"dmis-lab/biobert-base-cased-v1.2","metadata":{}}]}