{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1713918,"sourceType":"datasetVersion","datasetId":1015825},{"sourceId":10324487,"sourceType":"datasetVersion","datasetId":6392416},{"sourceId":10340932,"sourceType":"datasetVersion","datasetId":6403388}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:07:40.214460Z","iopub.execute_input":"2025-01-03T13:07:40.214720Z","iopub.status.idle":"2025-01-03T13:07:41.235097Z","shell.execute_reply.started":"2025-01-03T13:07:40.214668Z","shell.execute_reply":"2025-01-03T13:07:41.234102Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/genia-biomedical-event-dataset/train_data.csv\n/kaggle/input/genia-biomedical-event-dataset/test_data.csv\n/kaggle/input/genia-biomedical-event-dataset/dev_data.csv\n/kaggle/input/genia-biomedical-event-dataset/GE11-LICENSE\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizerFast, BertForTokenClassification, AdamW\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:07:41.236755Z","iopub.execute_input":"2025-01-03T13:07:41.237126Z","iopub.status.idle":"2025-01-03T13:07:58.196638Z","shell.execute_reply.started":"2025-01-03T13:07:41.237098Z","shell.execute_reply":"2025-01-03T13:07:58.195971Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_data(data, tokenizer, max_len):\n    sentences = []\n    labels = []\n\n    for _, row in data.iterrows():\n        sentence = row['Sentence'].split()\n        trigger_words = set(row['TriggerWord'].split(';')) if pd.notna(row['TriggerWord']) else set()\n        label = [1 if word in trigger_words else 0 for word in sentence]\n\n        sentences.append(sentence)\n        labels.append(label)\n\n    return sentences, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:07:58.197599Z","iopub.execute_input":"2025-01-03T13:07:58.198025Z","iopub.status.idle":"2025-01-03T13:07:58.203295Z","shell.execute_reply.started":"2025-01-03T13:07:58.197999Z","shell.execute_reply":"2025-01-03T13:07:58.202467Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Dummy dataset class\nclass WordClassificationDataset(Dataset):\n    def __init__(self, sentences, labels, tokenizer, max_len):\n        self.sentences = sentences\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        sentence = self.sentences[idx]\n        label = self.labels[idx]\n\n        encoding = self.tokenizer(\n            sentence,\n            is_split_into_words=True,\n            return_offsets_mapping=True,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_len\n        )\n\n        input_ids = encoding['input_ids']\n        attention_mask = encoding['attention_mask']\n\n        # Map labels to tokens\n        label_ids = [-100] * len(input_ids)\n        word_ids = encoding.word_ids()\n        for i, word_id in enumerate(word_ids):\n            if word_id is not None and i < len(label):\n                label_ids[i] = label[word_id]\n\n        return {\n            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n            'labels': torch.tensor(label_ids, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:07:58.204364Z","iopub.execute_input":"2025-01-03T13:07:58.204746Z","iopub.status.idle":"2025-01-03T13:07:58.238785Z","shell.execute_reply.started":"2025-01-03T13:07:58.204700Z","shell.execute_reply":"2025-01-03T13:07:58.237989Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Prepare data\nfile_path = '/kaggle/input/genia-biomedical-event-dataset/train_data.csv'\ndata = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:07:58.239869Z","iopub.execute_input":"2025-01-03T13:07:58.240451Z","iopub.status.idle":"2025-01-03T13:07:58.301366Z","shell.execute_reply.started":"2025-01-03T13:07:58.240422Z","shell.execute_reply":"2025-01-03T13:07:58.300733Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Parameters\nMAX_LEN = 128\nBATCH_SIZE = 16\nEPOCHS = 10\nLEARNING_RATE = 5e-5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:07:58.302548Z","iopub.execute_input":"2025-01-03T13:07:58.303199Z","iopub.status.idle":"2025-01-03T13:07:58.307658Z","shell.execute_reply.started":"2025-01-03T13:07:58.303155Z","shell.execute_reply":"2025-01-03T13:07:58.306714Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize tokenizer\ntokenizer = BertTokenizerFast.from_pretrained('dmis-lab/biobert-base-cased-v1.2')\n\n# Preprocess data\nsentences, labels = preprocess_data(data, tokenizer, MAX_LEN)\n\n# Create dataset and dataloader\ndataset = WordClassificationDataset(sentences, labels, tokenizer, MAX_LEN)\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:07:58.311151Z","iopub.execute_input":"2025-01-03T13:07:58.311763Z","iopub.status.idle":"2025-01-03T13:07:59.343955Z","shell.execute_reply.started":"2025-01-03T13:07:58.311733Z","shell.execute_reply":"2025-01-03T13:07:59.343199Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c670507fbfb46098f09ebcd17b9902b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dec72b424b8f43c48ae8378a4012a062"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Model\nmodel = BertForTokenClassification.from_pretrained('dmis-lab/biobert-base-cased-v1.2', num_labels=2)\nmodel = model.to('cuda')\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:07:59.344946Z","iopub.execute_input":"2025-01-03T13:07:59.345303Z","iopub.status.idle":"2025-01-03T13:08:02.402413Z","shell.execute_reply.started":"2025-01-03T13:07:59.345265Z","shell.execute_reply":"2025-01-03T13:08:02.401543Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e41fa705bc5444babe12125d474ea05f"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Training loop\ndef train(model, dataloader, optimizer, epochs):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        progress_bar = tqdm(dataloader, desc=f\"Training Epoch {epoch + 1}\", unit=\"batch\")\n        \n        for batch in progress_bar:\n            input_ids = batch['input_ids'].to('cuda')\n            attention_mask = batch['attention_mask'].to('cuda')\n            labels = batch['labels'].to('cuda')\n\n            optimizer.zero_grad()\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n\n        # Evaluate after each epoch\n        evaluate(model, dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:08:02.403531Z","iopub.execute_input":"2025-01-03T13:08:02.403835Z","iopub.status.idle":"2025-01-03T13:08:02.409622Z","shell.execute_reply.started":"2025-01-03T13:08:02.403808Z","shell.execute_reply":"2025-01-03T13:08:02.408633Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Evaluation function\ndef evaluate(model, dataloader):\n    model.eval()\n    predictions, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            input_ids = batch['input_ids'].to('cuda')\n            attention_mask = batch['attention_mask'].to('cuda')\n            labels = batch['labels'].to('cuda')\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n\n            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n            label_ids = labels.cpu().numpy()\n\n            for i, label in enumerate(label_ids):\n                true_labels.extend(label[label != -100])\n                predictions.extend(preds[i][label != -100])\n\n    print(classification_report(true_labels, predictions, digits=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:08:02.410774Z","iopub.execute_input":"2025-01-03T13:08:02.411134Z","iopub.status.idle":"2025-01-03T13:08:02.630312Z","shell.execute_reply.started":"2025-01-03T13:08:02.411072Z","shell.execute_reply":"2025-01-03T13:08:02.629505Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Run training\n#train(model, dataloader, optimizer, EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:08:02.631354Z","iopub.execute_input":"2025-01-03T13:08:02.631669Z","iopub.status.idle":"2025-01-03T13:08:02.638365Z","shell.execute_reply.started":"2025-01-03T13:08:02.631627Z","shell.execute_reply":"2025-01-03T13:08:02.637585Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Test model","metadata":{}},{"cell_type":"code","source":"# Prepare test data\nfile_path = '/kaggle/input/genia-biomedical-event-dataset/dev_data.csv'\ntest_data = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:13:21.827867Z","iopub.execute_input":"2025-01-03T13:13:21.828796Z","iopub.status.idle":"2025-01-03T13:13:21.861877Z","shell.execute_reply.started":"2025-01-03T13:13:21.828752Z","shell.execute_reply":"2025-01-03T13:13:21.861208Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Initialize tokenizer\ntokenizer = BertTokenizerFast.from_pretrained('dmis-lab/biobert-base-cased-v1.2')\n\n# Preprocess test data\ntest_sentences, test_labels = preprocess_data(test_data, tokenizer, MAX_LEN)\n\n# Create dataset and dataloader\ntest_dataset = WordClassificationDataset(test_sentences, test_labels, tokenizer, MAX_LEN)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:23:38.962751Z","iopub.execute_input":"2025-01-03T13:23:38.963125Z","iopub.status.idle":"2025-01-03T13:23:39.262040Z","shell.execute_reply.started":"2025-01-03T13:23:38.963093Z","shell.execute_reply":"2025-01-03T13:23:39.261308Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained('dmis-lab/biobert-base-cased-v1.2', num_labels=2)\nmodel = model.to('cuda')\nmodel.load_state_dict(torch.load('/kaggle/input/ee-pretrain-biobert/trigger-detection-biobert.pt', weights_only=True))\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:23:46.867864Z","iopub.execute_input":"2025-01-03T13:23:46.868226Z","iopub.status.idle":"2025-01-03T13:23:47.779871Z","shell.execute_reply.started":"2025-01-03T13:23:46.868196Z","shell.execute_reply":"2025-01-03T13:23:47.779005Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"evaluate(model, test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:23:50.873666Z","iopub.execute_input":"2025-01-03T13:23:50.874036Z","iopub.status.idle":"2025-01-03T13:24:13.417728Z","shell.execute_reply.started":"2025-01-03T13:23:50.874004Z","shell.execute_reply":"2025-01-03T13:24:13.416831Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.9901    0.9937    0.9919     70036\n           1     0.7933    0.7073    0.7478      2388\n\n    accuracy                         0.9843     72424\n   macro avg     0.8917    0.8505    0.8699     72424\nweighted avg     0.9836    0.9843    0.9838     72424\n\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# Save model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/model_checkpoint.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:08:02.639240Z","iopub.execute_input":"2025-01-03T13:08:02.639494Z","iopub.status.idle":"2025-01-03T13:08:03.422221Z","shell.execute_reply.started":"2025-01-03T13:08:02.639469Z","shell.execute_reply":"2025-01-03T13:08:03.421024Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T13:08:03.423627Z","iopub.execute_input":"2025-01-03T13:08:03.424098Z","iopub.status.idle":"2025-01-03T13:08:03.429565Z","shell.execute_reply.started":"2025-01-03T13:08:03.424046Z","shell.execute_reply":"2025-01-03T13:08:03.428653Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"download_file('/kaggle/working/model_checkpoint.pt', 'model')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"dmis-lab/biobert-base-cased-v1.2","metadata":{}}]}